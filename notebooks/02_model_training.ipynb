{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Passport Detection Project - Model Training\n",
                "\n",
                "**Student:** [Your Name]  \n",
                "**Project:** Fake Passport Detection Using CNN and Rule-Based Validation  \n",
                "**Purpose:** Educational demonstration of computer vision and deep learning\n",
                "\n",
                "---\n",
                "\n",
                "## ðŸ“š What This Notebook Does\n",
                "\n",
                "1. Load and preprocess passport images\n",
                "2. Handle class imbalance\n",
                "3. Build CNN model using transfer learning\n",
                "4. Train the model\n",
                "5. Evaluate performance\n",
                "6. Save trained model\n",
                "\n",
                "---\n",
                "\n",
                "## âš ï¸ IMPORTANT NOTES\n",
                "\n",
                "- Make sure you have dataset in correct folder structure\n",
                "- Training may take 30-60 minutes depending on your hardware\n",
                "- Model will be saved to `models/passport_cnn.h5`\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Import Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Basic imports\n",
                "import os\n",
                "import sys\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Deep learning\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "\n",
                "# Our custom modules\n",
                "sys.path.append('..')  # Add parent directory to path\n",
                "from src.data.preprocessing import create_data_generators, calculate_class_weights, visualize_samples\n",
                "from src.models.cnn_model import create_cnn_model, train_model, plot_training_history\n",
                "\n",
                "# Print TensorFlow version\n",
                "print(f\"âœ“ TensorFlow version: {tf.__version__}\")\n",
                "print(f\"âœ“ Keras version: {keras.__version__}\")\n",
                "\n",
                "# Check if GPU is available (optional, makes training faster)\n",
                "gpus = tf.config.list_physical_devices('GPU')\n",
                "if gpus:\n",
                "    print(f\"âœ“ GPU available: {len(gpus)} device(s)\")\n",
                "else:\n",
                "    print(\"âš  No GPU detected, training will use CPU (slower)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Set Up Project Paths\n",
                "\n",
                "Make sure your dataset is organized like this:\n",
                "\n",
                "```\n",
                "data/\n",
                "â”œâ”€â”€ train/\n",
                "â”‚   â”œâ”€â”€ real/\n",
                "â”‚   â””â”€â”€ fake/\n",
                "â”œâ”€â”€ validation/\n",
                "â”‚   â”œâ”€â”€ real/\n",
                "â”‚   â””â”€â”€ fake/\n",
                "â””â”€â”€ test/\n",
                "    â”œâ”€â”€ real/\n",
                "    â””â”€â”€ fake/\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define paths\n",
                "BASE_DIR = os.path.abspath('..')\n",
                "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
                "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
                "VAL_DIR = os.path.join(DATA_DIR, 'validation')\n",
                "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
                "MODEL_DIR = os.path.join(BASE_DIR, 'models')\n",
                "\n",
                "# Create models directory if it doesn't exist\n",
                "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                "\n",
                "# Check if directories exist\n",
                "print(\"Checking data directories...\")\n",
                "print(f\"Train directory: {TRAIN_DIR} - {'âœ“ Exists' if os.path.exists(TRAIN_DIR) else 'âœ— NOT FOUND'}\")\n",
                "print(f\"Validation directory: {VAL_DIR} - {'âœ“ Exists' if os.path.exists(VAL_DIR) else 'âœ— NOT FOUND'}\")\n",
                "print(f\"Test directory: {TEST_DIR} - {'âœ“ Exists' if os.path.exists(TEST_DIR) else 'âœ— NOT FOUND'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Create Data Generators\n",
                "\n",
                "Data generators:\n",
                "- Load images in batches (saves memory)\n",
                "- Apply data augmentation to training data\n",
                "- Normalize pixel values (0-1)\n",
                "\n",
                "**What is data augmentation?**  \n",
                "Creating slightly modified versions of images (rotation, brightness, etc.) to increase dataset variety and prevent overfitting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Creating data generators...\\n\")\n",
                "\n",
                "# Create generators\n",
                "train_generator, validation_generator = create_data_generators(TRAIN_DIR, VAL_DIR)\n",
                "\n",
                "# Display info\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"DATA GENERATOR SUMMARY\")\n",
                "print(f\"{'='*60}\")\n",
                "print(f\"Training samples: {train_generator.samples}\")\n",
                "print(f\"Validation samples: {validation_generator.samples}\")\n",
                "print(f\"Batch size: {train_generator.batch_size}\")\n",
                "print(f\"Classes: {train_generator.class_indices}\")\n",
                "print(f\"{'='*60}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Visualize Sample Images\n",
                "\n",
                "Let's look at some sample images to verify:\n",
                "1. Images are loading correctly\n",
                "2. Data augmentation is working\n",
                "3. Labels are correct"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Displaying sample training images with augmentation...\\n\")\n",
                "visualize_samples(train_generator, num_samples=9)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Calculate Class Weights\n",
                "\n",
                "**Why do we need class weights?**\n",
                "\n",
                "In real scenarios, we usually have:  \n",
                "- More REAL passport images\n",
                "- Fewer FAKE passport images\n",
                "\n",
                "This is called **class imbalance**.\n",
                "\n",
                "**Problem:**  \n",
                "Model might learn to just predict \"REAL\" all the time  \n",
                "(Example: With 300 real and 100 fake, always predicting REAL gives 75% accuracy!)\n",
                "\n",
                "**Solution:**  \n",
                "Give more weight to the minority class (fake)  \n",
                "This forces the model to learn both classes equally."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate class weights\n",
                "class_weights = calculate_class_weights(train_generator)\n",
                "\n",
                "print(\"\\nClass weights will be used during training to handle imbalance.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Create CNN Model\n",
                "\n",
                "**What is a CNN?**  \n",
                "Convolutional Neural Network - designed for image analysis.  \n",
                "Learns visual patterns automatically (edges â†’ textures â†’ objects)\n",
                "\n",
                "**What is transfer learning?**  \n",
                "Using a model already trained on millions of images (ImageNet)  \n",
                "Then fine-tuning it for our specific task (passport detection)\n",
                "\n",
                "**Our architecture:**\n",
                "1. **Base:** EfficientNetB0 (pre-trained)\n",
                "2. **Custom head:** Dense layers for passport classification\n",
                "3. **Output:** Sigmoid (probability 0-1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create model\n",
                "model = create_cnn_model()\n",
                "\n",
                "print(\"\\nâœ“ Model created successfully!\")\n",
                "print(f\"âœ“ Total parameters: {model.count_params():,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Train the Model\n",
                "\n",
                "**What happens during training?**\n",
                "\n",
                "1. Model looks at images\n",
                "2. Makes predictions\n",
                "3. Calculates how wrong it was (loss)\n",
                "4. Updates weights to improve\n",
                "5. Repeats for all images = 1 epoch\n",
                "6. Returns multiple epochs\n",
                "\n",
                "**Callbacks used:**\n",
                "- **Early Stopping:** Stop if no improvement\n",
                "- **Reduce LR:** Lower learning rate if stuck\n",
                "- **Model Checkpoint:** Save best model\n",
                "\n",
                "**This will take 30-60 minutes**  \n",
                "Go grab a coffee! â˜•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train model\n",
                "history = train_model(\n",
                "    model=model,\n",
                "    train_generator=train_generator,\n",
                "    validation_generator=validation_generator,\n",
                "    class_weights=class_weights,\n",
                "    epochs=20  # Will stop early if no improvement\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Visualize Training History\n",
                "\n",
                "**What to look for:**\n",
                "\n",
                "**GOOD SIGNS:**\n",
                "- Both training and validation accuracy increase\n",
                "- Both training and validation loss decrease\n",
                "- Curves are close to each other\n",
                "- Curves stabilize at the end\n",
                "\n",
                "**BAD SIGNS (overfitting):**\n",
                "- Training keeps improving, but validation stops or gets worse\n",
                "- Large gap between training and validation\n",
                "- Validation curve is very noisy\n",
                "\n",
                "**If overfitting occurs:**\n",
                "- Add more data augmentation\n",
                "- Increase dropout rate\n",
                "- Collect more training data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training curves\n",
                "plot_training_history(history)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: Evaluate on Test Set\n",
                "\n",
                "**Why test set?**  \n",
                "To evaluate model on completely unseen data  \n",
                "This simulates real-world performance\n",
                "\n",
                "**Metrics:**\n",
                "- **Accuracy:** Overall correctness\n",
                "- **Precision:** When model says FAKE, how often is it right?\n",
                "- **Recall:** Of all actual fakes, how many did we catch?\n",
                "- **F1-Score:** Balance between precision and recall"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "# Create test generator (no augmentation)\n",
                "test_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "test_generator = test_datagen.flow_from_directory(\n",
                "    TEST_DIR,\n",
                "    target_size=(224, 224),\n",
                "    batch_size=16,\n",
                "    class_mode='binary',\n",
                "    shuffle=False\n",
                ")\n",
                "\n",
                "# Evaluate\n",
                "print(\"Evaluating on test set...\\n\")\n",
                "test_loss, test_accuracy = model.evaluate(test_generator)\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"TEST SET RESULTS\")\n",
                "print(f\"{'='*60}\")\n",
                "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
                "print(f\"Test Loss: {test_loss:.4f}\")\n",
                "print(f\"{'='*60}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 10: Generate Confusion Matrix\n",
                "\n",
                "**What is a confusion matrix?**  \n",
                "Shows where the model makes mistakes:\n",
                "\n",
                "```\n",
                "                Predicted\n",
                "              FAKE    REAL\n",
                "Actual FAKE    TP      FN\n",
                "       REAL    FP      TN\n",
                "```\n",
                "\n",
                "- **TP (True Positive):** Correctly identified fakes\n",
                "- **TN (True Negative):** Correctly identified reals\n",
                "- **FP (False Positive):** Real marked as fake (bad!)\n",
                "- **FN (False Negative):** Fake marked as real (very bad!)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import confusion_matrix, classification_report\n",
                "import seaborn as sns\n",
                "\n",
                "# Get predictions\n",
                "predictions = model.predict(test_generator)\n",
                "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
                "true_classes = test_generator.classes\n",
                "\n",
                "# Compute confusion matrix\n",
                "cm = confusion_matrix(true_classes, predicted_classes)\n",
                "\n",
                "# Plot\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=['FAKE', 'REAL'],\n",
                "            yticklabels=['FAKE', 'REAL'])\n",
                "plt.ylabel('Actual')\n",
                "plt.xlabel('Predicted')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.show()\n",
                "\n",
                "# Print classification report\n",
                "print(\"\\nDetailed Metrics:\")\n",
                "print(\"=\"*60)\n",
                "target_names = ['FAKE', 'REAL']\n",
                "print(classification_report(true_classes, predicted_classes, target_names=target_names))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 11: Save the Model\n",
                "\n",
                "Save the trained model so we can use it later without retraining."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model is already saved by ModelCheckpoint callback\n",
                "# But let's also save the final version\n",
                "\n",
                "final_model_path = os.path.join(MODEL_DIR, 'passport_cnn_final.h5')\n",
                "model.save(final_model_path)\n",
                "\n",
                "print(f\"âœ“ Model saved to: {final_model_path}\")\n",
                "print(f\"âœ“ Best model saved to: {os.path.join(MODEL_DIR, 'passport_cnn.h5')}\")\n",
                "print(\"\\nâœ… Training complete! You can now use the model for predictions.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¯ Summary\n",
                "\n",
                "**What we accomplished:**\n",
                "1. âœ“ Loaded and preprocessed passport images\n",
                "2. âœ“ Applied data augmentation\n",
                "3. âœ“ Handled class imbalance with weights\n",
                "4. âœ“ Built CNN model using transfer learning\n",
                "5. âœ“ Trained model with callbacks\n",
                "6. âœ“ Evaluated performance on test set\n",
                "7. âœ“ Generated confusion matrix\n",
                "8. âœ“ Saved trained model\n",
                "\n",
                "**Next steps:**\n",
                "- Use Grad-CAM to visualize model attention\n",
                "- Implement rule-based validation\n",
                "- Create hybrid decision system\n",
                "- Build web interface with Streamlit\n",
                "\n",
                "---\n",
                "\n",
                "**For your report/presentation:**\n",
                "\n",
                "*\"I implemented a CNN-based passport verification system using transfer learning with EfficientNetB0. The model achieved [X]% accuracy on the test set. I addressed class imbalance using weighted loss and prevented overfitting through data augmentation and dropout. The system successfully combines deep learning with rule-based validation for improved robustness and interpretability.\"*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}